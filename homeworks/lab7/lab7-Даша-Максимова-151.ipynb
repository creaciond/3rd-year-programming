{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 7. Композиции алгоритмов. Градиентный бустинг. Ранжирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постарайтесь оформить всю работу как один монолитный рассказ/отчет. Избегайте дублирования кода. Избегайте использования циклов, вместо этого ищите готовый алгоритм в пакетах. Подписывайте все графики, а также их оси, если график содержит несколько кривых, то обязательно пользуйтесь легендой. Также неукоснительно соблюдайте PEP8. За несоблюдение этих простейших правил итоговые баллы могут быть снижены безапелляционно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (5 баллов) Bias-Variance decomposition.\n",
    "\n",
    "![](http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу регрессии со среднеквадратичной функцией потерь, а также некоторый алгорим $a$. Тогда качество алгоритма $a$ может быть записано следующим образом:\n",
    "\n",
    "$$Q(a) = \\mathbb{E}_{X^l} \\mathbb{E}_{x,y}\\left(a(x) - y\\right)^2$$\n",
    "\n",
    "где первое матожидание вычисляется по всевозможным обучающим выборкам $X^l$. К сожалению, на реальных данных эта формула неприменима из-за невозможности сгенерировать необходимые для оценки данные. Поэтому проведем приближенный численный эксперимент с эмпирическими оценками матожиданий.\n",
    "\n",
    "Обозначим вектор истинных меток тестовой выборки за $y \\in \\mathbb{R}^{l}$. С помощью бутстраппинга можно просемплировать из обучающей выборки $N$ новых выборок того же размера, тем самым \"имитируя\" пространство всевозможных обучающих выборок, после чего обучить на каждой выбранный алгоритм. Векторы прогнозов для объектов из тестовой выборки для каждой модели обозначим за $\\hat{y}_i \\in \\mathbb{R}^{l}, i \\in \\{1, .., N\\}$. Тогда средний квадрат ошибки по всем моделям на тестовой выборке запишется как\n",
    "\n",
    "$$error=\\frac{1}{N}\\sum_{i=1}^{N}MSE(y,\\hat{y}_i)$$\n",
    "\n",
    "Обозначим среднее предсказание за $$\\overline{y} = \\frac{1}{N}\\sum_{i=1}^{N} \\hat{y}_i$$\n",
    "\n",
    "Тогда квадрат отклонения среднего предсказания и разброс прогнозов относительно среднего предсказания всех моделей на тестовой выборке от истинных меток запишутся следующим образом, соответственно:\n",
    "\n",
    "$$bias^2 = MSE(y, \\overline y)$$\n",
    "\n",
    "$$variance = \\frac{1}{N}\\sum_{i=1}^N MSE(\\hat{y}_i, \\overline y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала рассмотрим в качестве алгоритма решающее дерево. Как известно, при увеличении высоты дерева алгоритм может быть сильно чувствителен к составу обучающей выборки. Чтобы подтвердить эти предположения, проведите следующие эксперименты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузите [набор данных](http://archive.ics.uci.edu/ml/datasets/BlogFeedback).** Каждый объект — пост в блоге. Он описывается различными признаками: длина текста поста, наличие наиболее частотных слов, день недели, количество комментариев за последние 24 часа и т.п., а так же целевым признаком — количеством комментариев к посту. Полный список признаков и описание находятся на странице датасета. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.44188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1    2      3     4         5         6    7      8    9    \\\n",
       "0  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "1  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "2  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "3  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "4  40.30467  53.845657  0.0  401.0  15.0  15.52416  32.44188  0.0  377.0  3.0   \n",
       "\n",
       "   ...   271  272  273  274  275  276  277  278  279   280  \n",
       "0  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
       "1  ...   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2  ...   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "3  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   1.0  \n",
       "4  ...   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  27.0  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/blogs/blogData_train.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбейте данные из файла `blogData_train.csv` на обучающую и тестовую выборки в пропорциях 1 к 4 соответственно.** Обратите внимание, что обучающая выборка меньше тестовой. Такая большая тестовая выборка позволит сделать измерение качества моделей достаточно достоверным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = np.arange(0,280)\n",
    "X = df[feature_cols].values\n",
    "y = df[280].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, test_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. (3 балла) Постройте графики зависимости $error$, $bias^2$ и $variance$ от глубины решающего дерева (от 1 до 15 включительно) для $N=100$. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425.1792 (error) = 1423.7849 (bias^2) + 1.3943 (var)\n"
     ]
    }
   ],
   "source": [
    "n_repeat = 15\n",
    "n_test = len(y_test)\n",
    "\n",
    "# Compute predictions\n",
    "y_predict = np.zeros((n_test, n_repeat))\n",
    "for i in range(n_repeat):\n",
    "    depth = i+1\n",
    "    tree = DecisionTreeClassifier(max_depth=depth, max_leaf_nodes=100)\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_predict[:, i] = tree.predict(X_test)\n",
    "\n",
    "# Bias^2 + Variance\n",
    "y_error = np.zeros(n_test)\n",
    "\n",
    "for i in range(n_repeat):\n",
    "    for j in range(n_repeat):\n",
    "        y_error += (y_test - y_predict[:, i]) ** 2\n",
    "\n",
    "y_error /= (n_repeat * n_repeat)\n",
    "\n",
    "y_bias = (y_test - np.mean(y_predict, axis=1)) ** 2\n",
    "y_var = np.var(y_predict, axis=1)\n",
    "\n",
    "print(\"{:.4f} (error) = {:.4f} (bias^2) + {:.4f} (var)\".format(np.mean(y_error),\n",
    "                                                                       np.mean(y_bias),\n",
    "                                                                       np.mean(y_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ad70ea5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(X_test, y_error, \"r\", label=\"$error(x)$\")\n",
    "plt.plot(X_test, y_bias, \"b\", label=\"$bias^2(x)$\")\n",
    "plt.plot(X_test, y_var, \"g\", label=\"$variance(x)$\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2. (2 балла)** Являются ли какие-то из полученных графиков монотонными? А должны ли они быть монотонными, если бы гипотетически эксперименты были проведены на всевозможных выборках? Почему? Убедитесь численно, что верно bias-variance разложение ошибки: $$error = bias^2 + variance$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (7 баллов) Композиции алгоритмов. Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на описанный выше недостаток решающих деревьев, объединение их в композиции позволяет существенно улучшить качество предсказания. Рассмотрим несколько способов построения композиций.\n",
    "\n",
    "#### Bagging + RSM\n",
    "\n",
    "![](https://sites.google.com/site/rajhansgondane2506/_/rsrc/1467898300734/publications/rrftrain.jpg?height=215&width=320)\n",
    "\n",
    "Один из способов объединения алгоритмов в композиции — обучение каждого отдельного алгоритма на некоторой подвыборке из исходной выборки ([bagging](https://en.wikipedia.org/wiki/Bootstrap_aggregating)) и подмножестве исходных признаков ([RSM](https://en.wikipedia.org/wiki/Random_subspace_method)). В sklearn этот тип композиции реализован в классе [BaggingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html) (для случая регресии). Подобный подход также есть в реализации [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Градиентный бустинг\n",
    "\n",
    "В случае бустинга композиция алгоритмов строится последовательно. Каждый следующий базовый алгоритм акцентируется на тех объектах, на которых обученная ранее композиция допускала ошибку.\n",
    "\n",
    "На данный момент одной из самых широко распространенных реализаций бустинга является библиотека [XGBoost](https://github.com/dmlc/xgboost). В ней большое внимание уделяется регуляризации и скорости, нежели в других реализациях бустинга (например,  [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) из sklearn). Кроме того, XGBoost позволяет оптимизировать различные функции потерь, а также более гибок, засчет большого числа параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost строит композицию из $K$ базовых алгоритмов $b_k$:\n",
    "\n",
    "$$ \\hat{y}_i = \\hat{y}_i^{K} = \\sum_{k=1}^{K} b_k(x_i) = \\hat{y}_i^{\\left(K - 1\\right)} + b_K(x_i), $$\n",
    "\n",
    "минимизируя следующий функционал:\n",
    "\n",
    "$$ Obj = \\sum_{i=1}^N \\mathcal{L}(y_i, \\hat{y}_i ) + \\sum_{k=1}^{K} \\Omega(b_k),$$\n",
    "\n",
    "где\n",
    " - $N$ — размер обучающей выборки;\n",
    " - $x_i, y_i, \\hat{y}_i$ — i-ый объект, правильный ответ и предсказание модели для него;\n",
    " - $\\hat{y}_i^{t}$ — предсказание композиции из $t$ уже обученных базовых алгоритмов для i-го объекта;\n",
    " - $\\Omega$ — регуляризатор;\n",
    " - $\\mathcal{L}(y_i, \\hat{y}_i)$ — функция потерь.\n",
    "\n",
    "Функционал, оптимизируемый на $t$-ой итерации:\n",
    "\n",
    "$$ Obj^{(t)} = \\sum_{i=1}^N \\mathcal{L}\\left(y_i, \\hat{y}_i^{(t-1)} + b_t(x_i)\\right) + \\Omega(b_t).$$\n",
    "\n",
    "В случае бустинга над решающими деревьями регуляризатор имеет следующий вид:\n",
    "\n",
    "$$ \\Omega(b_t) = \\gamma T + \\frac{1}{2}\\lambda\\sum_{j=1}^{T}w_j^2 + \\alpha\\sum_{j=1}^{T}w_j,$$\n",
    "\n",
    "где \n",
    " - $T$ — количество листьев в дереве;\n",
    " - $w_j$ — веса в листьях дерева;\n",
    " - $\\lambda, \\alpha, \\gamma$ — гиперпараметры.\n",
    "\n",
    "Данный регуляризатор подобран эвристически и хорошо показывает себя на практике. \n",
    "\n",
    "Раскладывая в ряд Тейлора выражение $\\mathcal{L}\\left(y_i, \\hat{y}_i^{\\left(t-1\\right)} + b_t(x_i)\\right)$ до второго порядка, получаем:\n",
    "\n",
    "$$ Obj^{(t)} = \\sum_{i=1}^N\\left[\\mathcal{L}(y_i, \\hat{y}_i^{\\left(t-1\\right)}) + g_{i}b_{t}(x_i) + \\frac{1}{2}h_{i}b_{t}^2(x_i)\\right] + \\Omega(b_t),$$\n",
    "\n",
    "где $g_i = \\partial_{\\hat{y}_i^{(t-1)}} \\mathcal{L}(y_i, \\hat{y_i}^{(t-1)})$, $h_i = \\partial_{\\hat{y}_i^{(t-1)}}^2 \\mathcal{L}(y_i, \\hat{y}_i^{(t-1)}) $ — градиент и гессиан оптимизируемой функции потерь.\n",
    "\n",
    "Приводя теперь подобные слагаемые и отбрасывая слагаемое $ \\mathcal{L}(y_i, \\hat{y}_i^{(t-1)}) $, не зависящее от $ b_t(x_i)$ (а следовательно, не влияющее на точку минимума функционала), получаем формулу:\n",
    "$$ Obj^{(t)} \\simeq \\sum_{j=1}^{T}\\left[\\sum_{i \\in I_j} g_i w_j + \\frac{1}{2}\\sum_{i \\in I_j} (h_i + \\lambda)w_j^2\\right] + \\gamma T$$\n",
    "$$ = \\sum_{j=1}^{T}\\left[G_jw_j + \\frac{1}{2}(H_j + \\lambda)w_j^2\\right] + \\gamma T, $$\n",
    "\n",
    "где \n",
    " - $ I_j $ - множество объектов обучающей выборки, попавших в $j$-ый лист дерева;\n",
    " - $ G_j = \\sum_{i \\in I_j} g_i$;\n",
    " - $ H_j = \\sum_{i \\in I_j} h_i$.\n",
    " \n",
    "Теперь, имея заданную структуру дерева, можно аналитически вычислить оптимальные значения для весов:\n",
    "$$ w_j^* = -\\frac{G_j}{H_j + \\lambda}.$$\n",
    "\n",
    "Значение функционала при этом будет равно:\n",
    "\n",
    "$$ Obj = -\\frac{1}{2}\\sum_{j=1}^T \\frac{G_j^2}{H_j + \\lambda} + \\gamma T .$$\n",
    "\n",
    "Осталось только построить дерево оптимальной структуры. Это можно делать известными методами построения решающих деревьев, проводя разбиения таким образом, чтобы максимизировать gain, определенный как уменьшение $Obj$ в момент этого разбиения. Для уже построенного дерева по формулам $ w_j^* $ вычисляются оптимальные значения в листьях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В XGBoost реализовано несколько различных функций потерь, что позволяет решать задачи классификации (бинарной и мультиклассовой), регрессии и ранжирования. Вот некоторые из них:\n",
    "\n",
    "- `reg:linear` — линейная регрессия\n",
    "- `reg:logistic` — логистическая регрессия\n",
    "- `binary:logistic` — логистическая регрессия\n",
    "- `multi:softmax` — softmax функция потерь для многоклассовой классификации\n",
    "- `rank:pairwise` — минимизация pairwise-функции потерь для задачи ранжирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. (4 балла)** Проведите аналогичный эксперимент с bias-variance разложением для градиентного бустинга для количество алгоритмов 1, 5, 10, 25 и 50, используя в качестве базовых алгоритмов решающие деревья. Пример использования библиотеки можно найти в туториале с семинара про XGBoost. Обратите внимание, что данная библиотека имеет два интерфейса (стандартный и аналог sklearn), названия параметров в которых могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. (3 балла)** Отличаются ли графики в рассмотренных моделях (решающее дерево, градиентный бустинг на решающих деревьях)  между собой? На какую компоненту из разложения ошибки влияет объединение алгоритмов в рассмотренный тип композиции?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. (15 баллов) Поисковое ранжирование\n",
    "\n",
    "![](http://i.imgur.com/2QnD2nF.jpg)\n",
    "\n",
    "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
    " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
    " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
    " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "\n",
    "#### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "\n",
    "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
    "\n",
    "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
    "\n",
    "Итоговая формула для расчета *nDCG*:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузите данные конкурса [Интернет-математика 2009](http://imat2009.yandex.ru/datasets).** Там же находится описание данных. **Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30.** Обратите внимание на формат данных: разбивать необходимо множество запросов, а не строчки датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам.\n",
    "\n",
    "**4. (3 балла) [Point-wise](https://en.wikipedia.org/wiki/Learning_to_rank#Pointwise_approach) подход. В этом случае значение функции потерь определяется по одному объекту, например, как в случае регрессии. Воспользовавшись известными вам техниками построения линейной регрессии, обучите модель, предсказывающую оценку асессора.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. (1 балл) [Pair-wise](https://en.wikipedia.org/wiki/Learning_to_rank#Pairwise_approach) подход. Здесь функция потерь вычисляется по паре объектов. Постройте ранжирующую модель при помощи [SVMlight](http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html), реализующий [Ranking SVM](https://en.wikipedia.org/wiki/Ranking_SVM).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Ранжируем с XGBoost\n",
    "\n",
    "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
    "1. **reg:linear** — эта функция потерь нужна для решения задачи регрессии, тем не менее, ее можно использовать в качестве ранжирующей point-wise модели.\n",
    "2. **rank:pairwise** — в качестве pairwise модели в XGBoost реализован [RankNet](http://research.microsoft.com/en-us/um/people/cburges/papers/ICML_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
    "3. **rank:map, rank:ndcg** — реализация [LambdaRank](http://research.microsoft.com/en-us/um/people/cburges/papers/lambdarank.pdf) для двух метрик: [MAP](https://www.kaggle.com/wiki/MeanAveragePrecision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса [list-wise](https://en.wikipedia.org/wiki/Learning_to_rank#Listwise_approach) моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. (3 балла) Обучите модели `rank:pairwise` и `rank:ndcg`, в качестве метрики оценки качества (`eval_metric`) используя `nDCG`, а в качестве бустера — решающее дерево. Рассмотрите различные [параметры](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md) бустера: `eta`, `gamma`, `tree_method`. Какие параметры сильнее всего влияют на качество?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пользовательская функция потерь\n",
    "\n",
    "Библиотека XGBoost позволяет использовать пользовательские функции потерь. Для этого необходимо реализовать функцию, принимающую на вход вектор предсказанных значений и обучающую выборку, и возвращающую градиент и гессиан, посчитанный по входным данным.\n",
    "\n",
    "Важно отметить, что XGBoost использует диагональную аппроксимацию гессиана, таким образом все недиагональные элементы считаются малозначимыми и приравниваются нулю, поэтому и градиент, и гессиан являются векторами длины размера обучающей выборки.\n",
    "\n",
    "**7. (5 баллов) Реализуйте экспоненциальную функцию потерь для XGBoost**:\n",
    "$$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = e^{-M} $$\n",
    "\n",
    "**Обучите модель с помощью данной функции потерь, настройте параметры.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарии к реализации**\n",
    "\n",
    "В случае ранжирования XGBoost'у необходимо знать о разбиении всех объектов на группы. В нашем случае в одну группу будут входить документы, соответствующие одному запросу. Функция, считающая градиент и гессиан по данным, должна знать данное разбиение датасета. Однако питоновский интерфейс класса *DMatrix* (в котором хранится датасет) не дает возможности получить это разбиение. В этом случае нужно реализовать функцию потерь в качестве функтора, конструктор которого принимает разбиение на группы в качестве параметра.\n",
    "\n",
    "В туториале с семинара есть пример реализации функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialPairwiseLoss(object):\n",
    "    def __init__(self, groups):\n",
    "        self.groups = groups\n",
    "                        \n",
    "    def __call__(self, preds, dtrain):\n",
    "        # your code here\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. (3 балла) Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:**\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного point-wise подхода с остальными моделями? \n",
    "   - согласуются ли результаты для *Ranking SVM* и *rank:pairwise*?\n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
