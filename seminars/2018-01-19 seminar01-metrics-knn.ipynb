{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Основные метрики машинного обучения. Метод k ближайших соседей (k nearest neighbours)\n",
    "Семинар 19 января 2018 г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "1. Разбиение выборки\n",
    "    * train и test\n",
    "    * кросс-валидация\n",
    "    \n",
    "2. Основные метрики\n",
    "    * accuracy\n",
    "    * precision (точность)\n",
    "    * recall (полнота)\n",
    "    * F-value (F-мера)\n",
    "\n",
    "2. Задача классификации: метод k ближайших соседей\n",
    "    * общий алгоритм\n",
    "    * реализация в ```sklearn``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пакеты \n",
    "Большинство алгоритмов машинного обучения уже реализованы в составе библиотеки [scikit-learn](http://scikit-learn.org/). Для того, чтобы она работала, нужно также установить [scipy](https://www.scipy.org/), [numpy](http://www.numpy.org/) и [matplotlib](https://matplotlib.org/). \n",
    "\n",
    "Полезные ссылки и документации:\n",
    "\n",
    "* документация scikit-learn лежит [вот тут](http://scikit-learn.org/stable/documentation.html),\n",
    "* туториалы по NumPy [на Хабре](https://habrahabr.ru/post/121031/),\n",
    "* туториалы по matplotlib [на сайте библиотеки](https://matplotlib.org/users/pyplot_tutorial.html),\n",
    "* список будет пополняться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение выборки\n",
    "\n",
    "### Тренировочные и тестовые данные\n",
    "Допустим, что у нас есть некоторое количество объектов, про которые нам известны и параметры объектов, и значения, которые должен выдать алгоритм. Логично разбить наши данные на _тренировочные_ (они же _train data_), которые мы \"скормим\" алгоритму для обучения, и _тестовые_ (_test data_), на которых мы будем проверять, как хорошо алгоритм схватил общий смысл данных. \n",
    "\n",
    "Вместе с этим нам важно избежать проблемы **переобучения**, когда алгоритм хорошо подстраивается под данные, на которых он учился, но плохо ловит тренд во всех остальных. \n",
    "\n",
    "#### Пропорции\n",
    "\n",
    "### Кросс-валидация\n",
    "Когда мы применяем _кросс-валидацию_, мы много раз разбиваем один и тот же набор данных на тренировочный и тестовый — как раз для того, чтобы избежать проблемы переобучения. \n",
    "\n",
    "**Как работает кросс-валидация**: данные разбиваются на k частей, из которых (k-1) часть используется для обучения и ещё одна — для теста. Процедура повторяется k раз, а после каждой итерации измеряется, как хорошо работал алгоритм. Среднее этих оценок будет максимально честной оценкой работы алгоритма. Такой процесс называется _k-fold cross-validation_.\n",
    "\n",
    "Как правило, такая кросс-валидация используется для алгоритмов регрессии, классификации и прогнозирования.\n",
    "\n",
    "### Как разбить данные автоматически?\n",
    "За нас уже подумали и всё реализовали в scikit-learn специальной функцией ```train_test_split()``` ([вот](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) её документация):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики в машинном обучении\n",
    "Мы можем реализовать много алгоритмов для решения одной и той же задачи, но при этом нам надо выбрать лучший из них. Для того, чтобы сделать это, мы используем различные **метрики**, которые помогают нам понять, как хорошо алгоритм справляется с задачей. Три самых распространённых метрики, используемых повсеместно — точность, полнота и F-мера.\n",
    "\n",
    "### Результат работы алгоритма\n",
    "Положим, что мы решаем задачу бинарной классификации, где каждому объекту присовоен свой класс — 0 или 1. Алгоритму подаётся признаковое описание объектов, а на выходе мы получаем значение класса _по мнению алгоритма_ — тоже 0 или 1. Таким образом, у нас получается 4 опции:\n",
    "\n",
    "* объект относится к классу 1, алгоритм определил как 1\n",
    "* объект относится к классу 1, алгоритм определил как 0\n",
    "* объект относится к классу 0, алгоритм определил как 1\n",
    "* объект относится к классу 0, алгоритм определил как 0\n",
    "\n",
    "|                 | 1 (на самом деле)    | 0 (на самом деле)      |\n",
    "| ----------------|:------------------:| :-------------------:|\n",
    "| **1 (алгоритм)** | true positive (TP) | false positive (FP) |\n",
    "| **0 (алгоритм)** | false negative (FN)| true negative (TN)  |\n",
    "\n",
    "\n",
    "### Метрики и их смысл\n",
    "\n",
    "#### Accuracy\n",
    "Самая простая метрика — accuracy — считает долю верно определённых элементов (и положительных, и отрицательных) по отношению ко всей выборке.\n",
    "$$accuracy = \\frac{TP + TN}{TP + FP + FN + TN}$$\n",
    "\n",
    "#### Precision, recall\n",
    "**Точность** (_precision_) — это метрика, описывающая, как точно алгоритм выбрал положительные примеры (т.е. она отвечает на вопрос _How many selected items are relevant?_). Точность считается в долях или в процентах.\n",
    "$$ precision = \\frac{TP}{TP + FP} $$\n",
    "\n",
    "**Полнота** (_recall_) — это метрика, описывающая, какая доля объектов положительного класса из всех найденных положительных действительно такие, то есть она отвечает на вопрос _How many relevant items are selected?_. Так же, как и точность, выражается в долях или процентах.\n",
    "$$ recall = \\frac{TP}{TP + FN} $$\n",
    "\n",
    "Точность и полноту хорошо описывает вот эта картинка из Википедии:\n",
    "![Precision, recall на картинке](https://habrastorage.org/web/38e/9d4/892/38e9d4892d9241ea95e1f56e3ef9124c.png \"Precision и recall\")\n",
    "\n",
    "#### F-мера\n",
    "Для того, чтобы максимально точно охарактеризовать корректность работы системы/алгоритма одним числом, использую так называемую **F-меру** (_F-score_, в формуле сокращён до $F$), которая, по сути, является средним гармоническим точности (в формуле сокращена до $P$) и полноты (в формуле сокращена до $R$).\n",
    "\n",
    "$$ F = 2\\cdot\\frac{P\\cdot R}{P + R} $$\n",
    "\n",
    "\n",
    "### Как посчитать метрики не руками?\n",
    "И снова на помощь приходит sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Y_train — значения тренировочной выборки, которые у нас в датасете\n",
    "# Y_out — результат работы алгоритма\n",
    "precision = metrics.precision_score(Y_train, Y_out)\n",
    "recall = metrics.recall_score(Y_train, Y_out)\n",
    "f1 = metrics.f1_score(Y_train, Y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод k ближайших соседей\n",
    "Метод **k ближайших соседей** (k nearest neightbours, kNN) — алгоритм, решающий задачу классификации как на двух-, так и на многомерном пространстве.\n",
    "\n",
    "_Общая формулировка задачи классификации:_ имеется множество объектов (ситуаций), разделённых некоторым образом на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Это множество называется обучающей выборкой. Классовая принадлежность остальных объектов не известна. Требуется построить алгоритм, способный классифицировать произвольный объект из исходного множества.\n",
    "\n",
    "### Side note: расстояния между объектами\n",
    "Возьмём две точки в пространстве. Когда мы говорим о _расстоянии_ между ними, мы чаще всего имеем в виду _евклидово расстояние_, то есть квадратный корень из квадрата разницы координат, взятых попарно:\n",
    "$$ d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$\n",
    "\n",
    "Соответственно, когда мы говорим о большем количестве измерений, изменяется количество пар координат.\n",
    "\n",
    "### Общее описание алгоритма\n",
    "Следующий алгоритм применяется для каждого объекта.\n",
    "\n",
    "1. Рассчитываются расстояния от каждого объекта выборки до выбраного. Они сортируются между собой.\n",
    "\n",
    "2. Выбираются k ближайших объектов (т.е. таких, расстояния от которых до выбранного/зафиксированного объекта будут минимальными).\n",
    "\n",
    "3. У каждого из этих k объектов мы смотрим на класс. \n",
    "\n",
    "4. Зафиксированному объекту мы присваиваем такой класс, которого больше всего среди k ближайших.\n",
    "\n",
    "### Прочее и разное (но важное) про kNN\n",
    "\n",
    "**1. Какое k выбрать?**\n",
    "\n",
    "k не должно быть слишком большим или слишком маленьким. Когда _k очень маленькое_, у нас недостаточно данных для определения класса. Когда _k очень большое_, мы задействуем в определении класса много \"шума\" и лишних объектов, т.к. учитываем даже объекты, находящиеся очень далеко от заданного.\n",
    "\n",
    "**2. Чётное или нечётное?**\n",
    "\n",
    "_Величина k **всегда должна быть нечётной**_, иначе алгоритм не всегда сможет правильно определить класс зафиксированного объекта. Например, при бинарной классификации может сложиться ситуация, когда равное количество объектов-соседей принадлежит к обоим классам — и что тогда делать?\n",
    "\n",
    "### Реализация в sckit\n",
    "Алгоритм уже реализован (см. пример на ирисах [вот тут](http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# создаём экзмепляр класса kNN\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "# методом fit() обучаем\n",
    "clf.fit(X_train, Y_train)\n",
    "# методом predict() заставляем классификатор работать на новых данных\n",
    "res = clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
